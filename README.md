# Local LLM with web ui

Run llama2

```shell
make run.llama2
```

[web-ui](127.0.0.1:3000)
